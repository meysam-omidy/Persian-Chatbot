{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch import nn\n",
    "\n",
    "def preprocess(text):\n",
    "    set1 = ['۱', '۲', '۳', '۴', '۵', '۶', '۷', '۸', '۹', '۰']\n",
    "    set2 = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "    t = str(text)\n",
    "    for s1, s2 in zip(set1, set2):\n",
    "        t = re.sub(s1, s2, t)\n",
    "    return t\n",
    "\n",
    "def extract_numbers(text):\n",
    "    t = re.sub('[^0-9]', ' ', str(text))\n",
    "    t = re.sub(r' +', ' ', t)\n",
    "    t = t.strip()\n",
    "    return t.split()\n",
    "\n",
    "class ChatBot():\n",
    "    def __init__(self, min_intent_accuracy, min_slots_accuracy) -> None:\n",
    "        self.min_intent_accuracy = min_intent_accuracy\n",
    "        self.min_slots_accuracy = min_slots_accuracy\n",
    "        self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "        self.num_interactions = 0\n",
    "        self.required_slots = []\n",
    "        self.base_text = ''\n",
    "        self.detected_intent = ''\n",
    "        self.detected_slots = {}\n",
    "        self.required_slot_not_accurate_text = None\n",
    "        self.required_slot_yes_no = False\n",
    "\n",
    "    def show_results(self):\n",
    "        print(\n",
    "            {\n",
    "                \"intent\": self.detected_intent,\n",
    "                \"parameters\": self.detected_slots\n",
    "            }\n",
    "        )\n",
    "        print(f'chatbot -> پایان عملیات {intent2persian[self.detected_intent]} | تعداد تعاملات {self.num_interactions}.')\n",
    "        print()\n",
    "\n",
    "    def get_intents_slots(self, text, base_text=''):\n",
    "        tokens = torch.tensor(tokenizer.encode(base_text + text)[:-1]).view(1,-1)\n",
    "        text_tokens_length = len(tokenizer.encode(text)[1:-1])\n",
    "        inputs = {}\n",
    "        inputs['input_ids'] = tokens.to(device)\n",
    "        inputs['token_type_ids'] = torch.zeros_like(tokens).to(device)\n",
    "        inputs['attention_mask'] = torch.ones_like(tokens).to(device)\n",
    "        pred_intents_logits, pred_slots_logits = model(inputs)\n",
    "        pred_slots = pred_slots_logits.argmax(dim=2)\n",
    "        pred_intent = pred_intents_logits.argmax(dim=1)\n",
    "        intent = number2intent[np.array(pred_intent.cpu())[0]]\n",
    "        slots = [number2slot[x] for x in np.array(pred_slots.cpu())[0]].copy()\n",
    "        slots_accuracy = [pred_slots_logits.softmax(dim=2)[0, i, pred_slots[0][i].item()].item() for i in range(pred_slots_logits.shape[1])]\n",
    "        intent_accuracy = pred_intents_logits.softmax(dim=1)[0, pred_intent.item()].item()\n",
    "        return intent, intent_accuracy, slots[-text_tokens_length:], slots_accuracy[-text_tokens_length:], list(np.array(tokens.reshape(-1)[1:].cpu()))[-text_tokens_length:]\n",
    "    \n",
    "    def fill_required_slots(self, text:str, slots:list, slots_accuracy:list, tokens:list):\n",
    "        required_slots = self.required_slots\n",
    "        required_slot_found = True\n",
    "        required_slot_not_accurate = False\n",
    "        for i,required_slot in enumerate(required_slots):\n",
    "            if slot2persian[required_slot].startswith('آیا'):\n",
    "                continue\n",
    "            start_index = -1\n",
    "            end_index = -1\n",
    "            if f'b-{required_slot}' in slots: start_index = slots.index(f'b-{required_slot}')\n",
    "            if f'i-{required_slot}' in slots: end_index = len(slots) - slots[-1::-1].index(f'i-{required_slot}')\n",
    "            if start_index == -1 and end_index == -1:\n",
    "                if i == 0 : \n",
    "                    required_slot_found = False\n",
    "            else:\n",
    "                if start_index == -1 and end_index != -1:\n",
    "                    start_index = slots.index(f'i-{required_slot}')\n",
    "                elif start_index != -1 and end_index == -1:\n",
    "                    end_index = len(slots) - slots[-1::-1].index(f'b-{required_slot}')\n",
    "                mean_accuracy = np.mean(slots_accuracy[start_index:end_index])\n",
    "                numbers = extract_numbers(text)\n",
    "                numbers_c = 0\n",
    "                decoded_texts = [tokenizer.decode([x]) for x in tokens][start_index:end_index]\n",
    "                for i in range(len(decoded_texts)):\n",
    "                    if decoded_texts[i] == '[UNK]':\n",
    "                        decoded_texts[i] = numbers[numbers_c]\n",
    "                        numbers_c += 1\n",
    "                if mean_accuracy > 0.9:\n",
    "                    self.required_slots.remove(required_slot)\n",
    "                    self.detected_slots[required_slot] = \" \".join(decoded_texts)\n",
    "                else:\n",
    "                    required_slot_not_accurate = True\n",
    "                    self.required_slot_not_accurate_text = \" \".join(decoded_texts)\n",
    "        if not required_slot_found:\n",
    "            return 'NOT_FOUND'\n",
    "        elif required_slot_not_accurate:\n",
    "            return 'NOT_ACCURATE'\n",
    "        else:\n",
    "            return 'FOUND'\n",
    "    \n",
    "    def handle_state(self, **kwargs):\n",
    "        if self.state == 'WAIT_FOR_INSTRUCTION':\n",
    "            text, intent, intent_accuracy, slots, slots_accuracy, tokens = kwargs['text'], kwargs['intent'], kwargs['intent_accuracy'], kwargs['slots'], kwargs['slots_accuracy'], kwargs['tokens']\n",
    "            # self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "            self.detected_intent = intent\n",
    "            self.base_text = f'{text} '\n",
    "            self.required_slots = intent2slots[intent].copy()\n",
    "            self.fill_required_slots(text, slots, slots_accuracy, tokens)\n",
    "            if intent_accuracy < 0.9:\n",
    "                self.state = 'CONFIRM_OPERATION'\n",
    "            else:\n",
    "                if len(self.required_slots) == 0:\n",
    "                    self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "                    self.show_results()\n",
    "                    self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "                else:\n",
    "                    self.state = 'GATHER_SLOTS'\n",
    "        elif self.state == 'CONFIRM_OPERATION':\n",
    "            text = kwargs['text']\n",
    "            if text == 'بله':\n",
    "                if len(self.required_slots) == 0:\n",
    "                    self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "                    self.show_results()\n",
    "                    self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "                else:\n",
    "                    self.state = 'GATHER_SLOTS'\n",
    "            elif text == 'خیر':\n",
    "                self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "            else:\n",
    "                intent, intent_accuracy, slots, slots_accuracy, tokens = self.get_intents_slots(text)    \n",
    "                self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "                self.handle_state(text=text, intent=intent, intent_accuracy=intent_accuracy, slots=slots, slots_accuracy=slots_accuracy, tokens=tokens)\n",
    "        elif self.state == 'GATHER_SLOTS':\n",
    "            text, intent, intent_accuracy, slots, slots_accuracy, tokens = kwargs['text'], kwargs['intent'], kwargs['intent_accuracy'], kwargs['slots'], kwargs['slots_accuracy'], kwargs['tokens']\n",
    "            if self.required_slot_yes_no:\n",
    "                if text == 'بله' or text == 'خیر':\n",
    "                    self.detected_slots[self.required_slots[0]] = text\n",
    "                    self.required_slots.remove(self.required_slots[0])\n",
    "                    self.required_slot_yes_no = False\n",
    "            else:\n",
    "                status = self.fill_required_slots(text, slots, slots_accuracy, tokens)\n",
    "                if status == 'FOUND':\n",
    "                    pass\n",
    "                elif status == 'NOT_FOUND':\n",
    "                    self.state = 'SLOT_NOT_FOUND'\n",
    "                elif status == 'NOT_ACCURATE':\n",
    "                    self.state = 'CONFIRM_SLOT'\n",
    "            if len(self.required_slots) == 0:\n",
    "                        self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "                        self.show_results()\n",
    "                        self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "        elif self.state == 'CONFIRM_SLOT':\n",
    "            text = kwargs['text']\n",
    "            if text == 'بله':\n",
    "                self.detected_slots[self.required_slots[0]] = self.required_slot_not_accurate_text\n",
    "                self.required_slot_not_accurate_text = None\n",
    "                self.required_slots.remove(self.required_slots[0])\n",
    "                if len(self.required_slots) == 0:\n",
    "                    self.state = 'WAIT_FOR_INSTRUCTION'\n",
    "                    self.show_results()\n",
    "                    self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "                else:\n",
    "                    self.state = 'GATHER_SLOTS'\n",
    "            elif text == 'خیر':\n",
    "                self.required_slot_not_accurate_text = None\n",
    "                self.state = 'GATHER_SLOTS'\n",
    "        elif self.state == 'SLOT_NOT_FOUND':\n",
    "            text, intent, intent_accuracy, slots, slots_accuracy, tokens = kwargs['text'], kwargs['intent'], kwargs['intent_accuracy'], kwargs['slots'], kwargs['slots_accuracy'], kwargs['tokens']\n",
    "            self.state = 'GATHER_SLOTS'\n",
    "            self.handle_state(text=text, intent=intent, intent_accuracy=intent_accuracy, slots=slots, slots_accuracy=slots_accuracy, tokens=tokens)\n",
    "\n",
    "    def get_prompt(self):\n",
    "        if self.state == 'WAIT_FOR_INSTRUCTION':\n",
    "            prompt = 'با سلام، چگونه میتوانم کمکتان کنم؟'\n",
    "        elif self.state == 'CONFIRM_OPERATION':\n",
    "            translated_intent = intent2persian[self.detected_intent]\n",
    "            prompt = f'آیا قصد انجام عملیات {translated_intent} را دارید؟ پاسخ شما میتواند بله یا خیر یا ذکر عملیات مورد نظر با جزئیات بیشتر باشد.'\n",
    "        elif self.state == 'GATHER_SLOTS':\n",
    "            if slot2persian[self.required_slots[0]].startswith('آیا'):\n",
    "                prompt = f'{slot2persian[self.required_slots[0]]} (با بله یا خیر پاسخ دهید)'\n",
    "                self.required_slot_yes_no = True\n",
    "            else:\n",
    "                prompt = f'لطفا {slot2persian[self.required_slots[0]]} را وارد کنید. (میتوانید در صورت تمایل اطلاعات ضروری دیگری نیز وارد کنید)'\n",
    "        elif self.state == 'CONFIRM_SLOT':\n",
    "            prompt = f'آیا {slot2persian[self.required_slots[0]]} ، {self.required_slot_not_accurate_text} است؟ (با بله یا خیر پاسخ دهید)'\n",
    "        elif self.state == 'SLOT_NOT_FOUND':\n",
    "            prompt = f'{slot2persian[self.required_slots[0]]} به درستی وارد نشد. لطفا مقدار درست آنرا وارد کنید.'\n",
    "        return prompt\n",
    "\n",
    "    def chat(self):\n",
    "        last_command_ran = True\n",
    "        while True:\n",
    "            prompt = self.get_prompt()\n",
    "            text = input()\n",
    "            text = preprocess(text)\n",
    "            if last_command_ran:\n",
    "                print(f'chatbot -> {prompt}' )\n",
    "            if text == '':\n",
    "                last_command_ran = False\n",
    "                continue\n",
    "            print(f'user    -> {text}', )\n",
    "            self.num_interactions += 1\n",
    "            if text == 'خروج':\n",
    "                break\n",
    "            elif text == 'لغو':\n",
    "                self.__init__(self.min_intent_accuracy, self.min_slots_accuracy)\n",
    "                last_command_ran = True\n",
    "                continue\n",
    "            if self.state == 'WAIT_FOR_INSTRUCTION':\n",
    "                intent, intent_accuracy, slots, slots_accuracy, tokens = self.get_intents_slots(text)\n",
    "                self.handle_state(text=text, intent=intent, intent_accuracy=intent_accuracy, slots=slots, slots_accuracy=slots_accuracy, tokens=tokens)\n",
    "            elif self.state == 'CONFIRM_OPERATION':\n",
    "                self.handle_state(text=text)\n",
    "            elif self.state == 'GATHER_SLOTS':\n",
    "                intent, intent_accuracy, slots, slots_accuracy, tokens = self.get_intents_slots(f'{slot2persian[self.required_slots[0]]} {text}', self.base_text)\n",
    "                self.handle_state(text=text, intent=intent, intent_accuracy=intent_accuracy, slots=slots, slots_accuracy=slots_accuracy, tokens=tokens)\n",
    "            elif self.state == 'CONFIRM_SLOT':\n",
    "                self.handle_state(text=text)\n",
    "            elif self.state == 'SLOT_NOT_FOUND':\n",
    "                intent, intent_accuracy, slots, slots_accuracy, tokens = self.get_intents_slots(f'{slot2persian[self.required_slots[0]]} {text}', self.base_text)\n",
    "                self.handle_state(text=text, intent=intent, intent_accuracy=intent_accuracy, slots=slots, slots_accuracy=slots_accuracy, tokens=tokens)\n",
    "            last_command_ran = True\n",
    "\n",
    "\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self, bert, num_slots, num_intents) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.intent_fc = nn.Linear(bert.config.hidden_size, num_intents)\n",
    "        self.slot_fc = nn.Linear(bert.config.hidden_size, num_slots)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(**x).last_hidden_state\n",
    "        return self.intent_fc(x[:, 0]), self.slot_fc(x[:, 1:])\n",
    "\n",
    "\n",
    "with open(\"nlu_project_saves/nlu_project_slot2number.json\", \"r\", encoding='utf8') as file:\n",
    "    slot2number = json.load(file)\n",
    "with open(\"nlu_project_saves/nlu_project_intent2number.json\", \"r\", encoding='utf8') as file:\n",
    "    intent2number = json.load(file)    \n",
    "with open('nlu_project_saves/nlu_project_intent2persian.json', 'r', encoding='utf8') as file:\n",
    "    intent2persian = json.load(file)\n",
    "with open('nlu_project_saves/nlu_project_slot2persian.json', 'r', encoding='utf8') as file:\n",
    "    slot2persian = json.load(file)\n",
    "intent2slots = {}\n",
    "for obj in json.load(open('./nlu_project_saves/nlu_project_intents-slots.json', 'r', encoding='utf8')):\n",
    "    intent2slots[obj['intent']] = obj['slots']\n",
    "number2slot = {slot2number[slot]:slot for slot in list(slot2number.keys())}\n",
    "\n",
    "number2intent = {intent2number[intent]:intent for intent in list(intent2number.keys())}\n",
    "tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-base-parsbert-uncased')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MainModel(BertModel.from_pretrained('./nlu_project_saves/nlu_project_bert/'), len(slot2number.keys()), len(intent2number.keys())).to(device)\n",
    "model.intent_fc.load_state_dict(torch.load('nlu_project_saves/nlu_project_intent.pth', map_location='cuda'))\n",
    "model.slot_fc.load_state_dict(torch.load('nlu_project_saves/nlu_project_slot.pth', map_location='cuda'))\n",
    "\n",
    "\n",
    "chatbot = ChatBot(min_intent_accuracy=0.9, min_slots_accuracy=0.8)\n",
    "chatbot.chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
